{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and own functions from functions.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "from functions import AddBinaryString, Scoring,plot3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUser         = pd.read_csv(\"../applicant_material/user.csv\") \n",
    "dfJobs         = pd.read_csv(\"../applicant_material/job_desc.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Delete strings in user_id and create concat the two dataframes\n",
    "dfUser.user_id = dfUser.user_id.apply(lambda x : int(x[1:]))\n",
    "dfJobs.user_id = dfJobs.user_id.apply(lambda x : int(x[1:]))\n",
    "dfAll          = pd.concat([dfUser, dfJobs], axis=1)\n",
    "\n",
    "#replace brackes by spaces, make all letters lowercase\n",
    "dfJobs.job_title_full = dfJobs.job_title_full.str.replace('(', ' ')\n",
    "dfJobs.job_title_full = dfJobs.job_title_full.str.replace(')', ' ')\n",
    "dfJobs.job_title_full = dfJobs.job_title_full.str.lower();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Prepare jobs-data (one-hot encoding of strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize data\n",
    "salaryBool         = True\n",
    "keywordsBool       = False\n",
    "categCompaniesBool = False\n",
    "categJobDescrBool  = False\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "if salaryBool:\n",
    "    dfJobs['Salary_Bool']  = np.where(dfJobs.salary.notnull(), 1, 0)\n",
    "\n",
    "#One-hot encoding keywords in job-description\n",
    "if keywordsBool:  \n",
    "    ListOfMostCommonWords = Counter(\" \".join(dfJobs[\"job_title_full\"]).split()).most_common(n = None)\n",
    "    ListOfStrings         = [entry for entry, count in ListOfMostCommonWords]\n",
    "    #ListOfStrings            = ['Manager','Junior','Senior', 'Lead', 'Remote', 'M/F', 'Backend','Analyst']\n",
    "    #ListOfStrings            = ['product','machine','apac', 'pricing', 'manager', 'pricing', 'ux', 'owner','checkout']\n",
    "    dfJobs                = AddBinaryString(dfJobs,ListOfStrings)\n",
    "\n",
    "#Categorize Companies /or job_descr\n",
    "if categCompaniesBool:\n",
    "    dfJobsDummies         = pd.get_dummies(dfJobs, columns=['company'])  \n",
    "    dfJobs = dfJobsDummies\n",
    "elif categJobDescrBool:\n",
    "    dfJobsDummies         = pd.get_dummies(dfJobs, columns=['job_title_full']) \n",
    "    dfJobs = dfJobsDummies\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "dfJobs.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label the feature set\n",
    "featureName = 'Full'       \n",
    "\n",
    "#Select from which datasets we want which columns\n",
    "jobsBool    = True\n",
    "userBool    = True\n",
    "dropColJobs = ['job_title_full', 'user_id','company', 'job_title_full']   #columns to drop in Jobs dataframe\n",
    "dropColUser = ['has_applied','user_id']                                   #columns to drop in User dataframe\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "if jobsBool and userBool:\n",
    "    features      = pd.concat([ dfJobs.drop(dropColJobs,axis = 1), \n",
    "                         dfUser.drop(dropColUser,axis =1)], axis=1)\n",
    "elif jobsBool:\n",
    "    features      = dfJobs.drop(dropColJobs,axis = 1)\n",
    "elif userBool:\n",
    "    features     = dfUser.drop(dropColUser, axis = 1 )\n",
    "\n",
    "    \n",
    "print('#####################################################################################'\n",
    "      '\\n# The by-hand selected features in the set named \"{0}\" are:  \\n#######################\\n\\n'.format(featureName),list(features.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data, data scaling, feature selection/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features and target variable\n",
    "X, y = features, dfUser.has_applied\n",
    "\n",
    "fillnan        = 'mean'\n",
    "featureSelBool = False\n",
    "polyBool       = False\n",
    "scalingBool    = True\n",
    "PCABool        = False\n",
    "\n",
    "\n",
    "\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "##Fill nan's with mean\n",
    "if fillnan == 'mean':\n",
    "    trainX = trainX.fillna(trainX.mean())\n",
    "    testX  = testX.fillna(testX.mean());\n",
    "    X      = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "#Tree Select Features\n",
    "if featureSelBool:\n",
    "    clf = ExtraTreesClassifier(n_estimators=50)\n",
    "    clf = clf.fit(trainX, trainy)\n",
    "    clf.feature_importances_  \n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    testX,trainX, X = model.transform(testX),model.transform(trainX),model.transform(X)\n",
    "\n",
    "    clf = ExtraTreesClassifier(n_estimators=50)\n",
    "    clf = clf.fit(X, y)\n",
    "    clf.feature_importances_  \n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    X = model.transform(X)\n",
    "    print(trainX.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Polynomial features\n",
    "if polyBool:\n",
    "    poly   = preprocessing.PolynomialFeatures(degree=2, interaction_only=False)\n",
    "    trainX = poly.fit_transform(trainX)\n",
    "    testX  = poly.fit_transform(testX)\n",
    "\n",
    "#Scaling\n",
    "if scalingBool:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(trainX)\n",
    "    # Apply transform to both the training set and the test set.\n",
    "    trainX, testX = scaler.transform(trainX) ,  scaler.transform(testX)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X      = scaler.transform(X)\n",
    "\n",
    "#PCA\n",
    "if PCABool:\n",
    "    pca = PCA(.9)\n",
    "    pca.fit(trainX)\n",
    "    trainX = pca.transform(trainX)\n",
    "    testX  = pca.transform(testX)\n",
    "    pca.fit(X)\n",
    "    X     = pca.transform(X)\n",
    "\n",
    "\n",
    "##Initialize Score variables\n",
    "scores    = []\n",
    "scoresAuc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name Class Technique\n",
    "clTechnique = 'Logistic'\n",
    "\n",
    "model       = LogisticRegression(solver='lbfgs'   ) #,max_iter = 10000)\n",
    "model.fit(trainX, trainy)\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr = Scoring(model, testX,testy, featureName, clTechnique =clTechnique,)\n",
    "scores.append( [fpr,tpr, featureName + '_' + clTechnique])\n",
    "\n",
    "\n",
    "mean_auc,std_auc = plot3(model, X,y, featureName, clTechnique,)\n",
    "scoresAuc.append([mean_auc,std_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clTechnique = 'SVM'\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1, probability = True).fit(trainX, trainy)\n",
    "print(clf.score(testX, testy))\n",
    "\n",
    "fpr, tpr = Scoring(clf = clf, testX = testX, testy = testy, featureName = featureName, clTechnique = clTechnique)\n",
    "scores.append( [fpr,tpr, featureName + '_' + clTechnique])\n",
    "\n",
    "\n",
    "mean_auc,std_auc = plot3(clf, X,y, featureName, clTechnique,)\n",
    "scoresAuc.append([mean_auc,std_auc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross-validatoin\n",
    "auc = cross_val_score(clf, trainX, trainy, scoring='roc_auc', cv = 10)\n",
    "print(auc)\n",
    "#get the mean of each fold \n",
    "print(\"AUC of Model with Cross Validation is:\",auc.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
    "clTechnique = 'DecTree'\n",
    "\n",
    "valX, test2X, valy, test2y = train_test_split(testX, testy, test_size=0.5, random_state=3)\n",
    "\n",
    "xg_class     = xgb.XGBClassifier(max_depth = 1)\n",
    "\n",
    "eval_set     = [(valX, valy)]\n",
    "xg_class.fit(trainX, trainy, eval_metric=\"auc\", eval_set=eval_set, verbose=False);\n",
    "\n",
    "fpr, tpr = Scoring(clf = xg_class, testX = test2X, testy = test2y, featureName = featureName, clTechnique = clTechnique)\n",
    "scores.append( [fpr,tpr, featureName + '_' + clTechnique])\n",
    "\n",
    "mean_auc,std_auc = plot3(xg_class, X,y, featureName, clTechnique,)\n",
    "scoresAuc.append([mean_auc,std_auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV1\n",
    "auc = cross_val_score(xg_class, X, y, scoring='roc_auc', cv = 10)\n",
    "print(auc)\n",
    "#get the mean of each fold \n",
    "print(\"Auc of Model with Cross Validation is:\",auc.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xg_class = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=20)\n",
    "\n",
    "plt.figsize=(50,10)\n",
    "xgb.plot_tree(xg_class,num_trees=0,)\n",
    "plt.savefig('Tree'+ featureName + '.pdf', dpi = 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clTechnique = 'RandomForest'\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=500);\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(trainX,trainy);\n",
    "\n",
    "fpr, tpr  = Scoring(clf = clf, testX = testX, testy = testy, featureName = featureName, clTechnique = clTechnique);\n",
    "scores.append( [fpr,tpr, featureName + '_' + clTechnique])\n",
    "\n",
    "mean_auc,std_auc = plot3(clf, X,y, featureName, clTechnique,)\n",
    "scoresAuc.append([mean_auc,std_auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV1\n",
    "auc = cross_val_score(clf, X, y, scoring='roc_auc', cv = 10)\n",
    "print(auc)\n",
    "#get the mean of each fold \n",
    "print(\"Auc of Model with Cross Validation is:\",auc.mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clTechnique = 'Neuronal'\n",
    "clf = MLPClassifier(solver='adam', activation='relu',\n",
    "                    hidden_layer_sizes=(3,3), random_state=1, max_iter = 1000,validation_fraction=0.2,learning_rate_init=0.001,shuffle = True);\n",
    "clf.fit(trainX, trainy);\n",
    "\n",
    "Scoring(clf = clf, testX = testX, testy = testy, featureName = featureName, clTechnique = clTechnique);\n",
    "\n",
    "mean_auc,std_auc = plot3(clf, X,y, featureName, clTechnique,)\n",
    "scoresAuc.append([mean_auc,std_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = cross_val_score(xg_class, X, y, scoring='roc_auc', cv = 10)\n",
    "print(auc)\n",
    "#get the mean of each fold \n",
    "print(\"Auc of Model with Cross Validation is:\",auc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AUC as a func of sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(trainX.shape)\n",
    "\n",
    "Ns = [250,500,750,1000,1200,1400,1599]\n",
    "\n",
    "clTechnique = 'RandomForest'\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=500);\n",
    "\n",
    "aucs    = []\n",
    "aucsStd = []\n",
    "testedScore = []\n",
    "\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    index = np.random.randint(0, len(trainX), N)\n",
    "    trainXcut = np.asarray(trainX)[index]\n",
    "    trainycut = np.asarray(trainy)[index]\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)    \n",
    "    auc = cross_val_score(clf, trainXcut, trainycut, scoring='roc_auc', cv = 10)\n",
    "    print(\"Auc of Model with Cross Validation is:\",auc.mean() )\n",
    "    aucs.append(auc.mean())\n",
    "    aucsStd.append(auc.std())\n",
    "    \n",
    "    clf.fit(trainXcut,trainycut);    \n",
    "    lr_probs     = clf.predict_proba(testX)\n",
    "    lr_probs     = lr_probs[:, 1]\n",
    "    testedScore.append( roc_auc_score(testy, lr_probs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot auc as function of sample-size\n",
    "fig,ax = plt.subplots(figsize = (3.3,2.2)) \n",
    "plt.errorbar(Ns,aucs,aucsStd, color = 'C0', lw = 1, label = 'AUC Cross Val')\n",
    "plt.plot(Ns,testedScore, '*-C1', markersize = 5, lw =1, label = 'AUC Test Data')\n",
    "plt.legend()\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Sample size')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/AUC_vs_sampleSize2.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
